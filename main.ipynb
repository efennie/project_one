{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e24e1afceeac59cef4f228f547d04fddd71b82b5af8ec9fc8b351df6cdccf2ba",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             date  average_price  total_volume        4046       4225  \\\n",
       "0      2015-01-04           1.22      40873.28     2819.50   28287.42   \n",
       "1      2015-01-04           1.79       1373.95       57.42     153.88   \n",
       "2      2015-01-04           1.00     435021.49   364302.39   23821.16   \n",
       "3      2015-01-04           1.76       3846.69     1500.15     938.35   \n",
       "4      2015-01-04           1.08     788025.06    53987.31  552906.04   \n",
       "...           ...            ...           ...         ...        ...   \n",
       "33040  2020-11-29           1.47    1583056.27    67544.48   97996.46   \n",
       "33041  2020-11-29           0.91    5811114.22  1352877.53  589061.83   \n",
       "33042  2020-11-29           1.48     289961.27    13273.75   19341.09   \n",
       "33043  2020-11-29           0.67     822818.75   234688.01   80205.15   \n",
       "33044  2020-11-29           1.35      24106.58     1236.96     617.80   \n",
       "\n",
       "           4770  total_bags  small_bags  large_bags  xlarge_bags  \\\n",
       "0         49.90     9716.46     9186.93      529.53         0.00   \n",
       "1          0.00     1162.65     1162.65        0.00         0.00   \n",
       "2         82.15    46815.79    16707.15    30108.64         0.00   \n",
       "3          0.00     1408.19     1071.35      336.84         0.00   \n",
       "4      39995.03   141136.68   137146.07     3990.61         0.00   \n",
       "...         ...         ...         ...         ...          ...   \n",
       "33040   2617.17  1414878.10   906711.52   480191.83     27974.75   \n",
       "33041  19741.90  3790665.29  2197611.02  1531530.14     61524.13   \n",
       "33042    636.51   256709.92   122606.21   134103.71         0.00   \n",
       "33043  10543.63   497381.96   285764.11   210808.02       809.83   \n",
       "33044   1564.98    20686.84    17824.52     2862.32         0.00   \n",
       "\n",
       "               type  year             geography  \n",
       "0      conventional  2015                Albany  \n",
       "1           organic  2015                Albany  \n",
       "2      conventional  2015               Atlanta  \n",
       "3           organic  2015               Atlanta  \n",
       "4      conventional  2015  Baltimore/Washington  \n",
       "...             ...   ...                   ...  \n",
       "33040       organic  2020            Total U.S.  \n",
       "33041  conventional  2020                  West  \n",
       "33042       organic  2020                  West  \n",
       "33043  conventional  2020   West Tex/New Mexico  \n",
       "33044       organic  2020   West Tex/New Mexico  \n",
       "\n",
       "[33045 rows x 13 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>average_price</th>\n      <th>total_volume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>total_bags</th>\n      <th>small_bags</th>\n      <th>large_bags</th>\n      <th>xlarge_bags</th>\n      <th>type</th>\n      <th>year</th>\n      <th>geography</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-01-04</td>\n      <td>1.22</td>\n      <td>40873.28</td>\n      <td>2819.50</td>\n      <td>28287.42</td>\n      <td>49.90</td>\n      <td>9716.46</td>\n      <td>9186.93</td>\n      <td>529.53</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-01-04</td>\n      <td>1.79</td>\n      <td>1373.95</td>\n      <td>57.42</td>\n      <td>153.88</td>\n      <td>0.00</td>\n      <td>1162.65</td>\n      <td>1162.65</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2015</td>\n      <td>Albany</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-01-04</td>\n      <td>1.00</td>\n      <td>435021.49</td>\n      <td>364302.39</td>\n      <td>23821.16</td>\n      <td>82.15</td>\n      <td>46815.79</td>\n      <td>16707.15</td>\n      <td>30108.64</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Atlanta</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-01-04</td>\n      <td>1.76</td>\n      <td>3846.69</td>\n      <td>1500.15</td>\n      <td>938.35</td>\n      <td>0.00</td>\n      <td>1408.19</td>\n      <td>1071.35</td>\n      <td>336.84</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2015</td>\n      <td>Atlanta</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-01-04</td>\n      <td>1.08</td>\n      <td>788025.06</td>\n      <td>53987.31</td>\n      <td>552906.04</td>\n      <td>39995.03</td>\n      <td>141136.68</td>\n      <td>137146.07</td>\n      <td>3990.61</td>\n      <td>0.00</td>\n      <td>conventional</td>\n      <td>2015</td>\n      <td>Baltimore/Washington</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33040</th>\n      <td>2020-11-29</td>\n      <td>1.47</td>\n      <td>1583056.27</td>\n      <td>67544.48</td>\n      <td>97996.46</td>\n      <td>2617.17</td>\n      <td>1414878.10</td>\n      <td>906711.52</td>\n      <td>480191.83</td>\n      <td>27974.75</td>\n      <td>organic</td>\n      <td>2020</td>\n      <td>Total U.S.</td>\n    </tr>\n    <tr>\n      <th>33041</th>\n      <td>2020-11-29</td>\n      <td>0.91</td>\n      <td>5811114.22</td>\n      <td>1352877.53</td>\n      <td>589061.83</td>\n      <td>19741.90</td>\n      <td>3790665.29</td>\n      <td>2197611.02</td>\n      <td>1531530.14</td>\n      <td>61524.13</td>\n      <td>conventional</td>\n      <td>2020</td>\n      <td>West</td>\n    </tr>\n    <tr>\n      <th>33042</th>\n      <td>2020-11-29</td>\n      <td>1.48</td>\n      <td>289961.27</td>\n      <td>13273.75</td>\n      <td>19341.09</td>\n      <td>636.51</td>\n      <td>256709.92</td>\n      <td>122606.21</td>\n      <td>134103.71</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2020</td>\n      <td>West</td>\n    </tr>\n    <tr>\n      <th>33043</th>\n      <td>2020-11-29</td>\n      <td>0.67</td>\n      <td>822818.75</td>\n      <td>234688.01</td>\n      <td>80205.15</td>\n      <td>10543.63</td>\n      <td>497381.96</td>\n      <td>285764.11</td>\n      <td>210808.02</td>\n      <td>809.83</td>\n      <td>conventional</td>\n      <td>2020</td>\n      <td>West Tex/New Mexico</td>\n    </tr>\n    <tr>\n      <th>33044</th>\n      <td>2020-11-29</td>\n      <td>1.35</td>\n      <td>24106.58</td>\n      <td>1236.96</td>\n      <td>617.80</td>\n      <td>1564.98</td>\n      <td>20686.84</td>\n      <td>17824.52</td>\n      <td>2862.32</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2020</td>\n      <td>West Tex/New Mexico</td>\n    </tr>\n  </tbody>\n</table>\n<p>33045 rows Ã— 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "#read initial csv into a dataframe\n",
    "csv_file = 'Main Avocado Tree (Resources)/avocado-updated-2020.csv'\n",
    "avocado_df = pd.read_csv(csv_file)\n",
    "avocado_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Geography State  Year  Per capita personal income\n",
       "0                  Abilene    TX  2017                       40876\n",
       "1                    Akron    OH  2017                       47522\n",
       "2                   Albany    GA  2017                       36780\n",
       "3           Albany-Lebanon    OR  2017                       41169\n",
       "4  Albany-Schenectady-Troy    NY  2017                       56487"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Geography</th>\n      <th>State</th>\n      <th>Year</th>\n      <th>Per capita personal income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abilene</td>\n      <td>TX</td>\n      <td>2017</td>\n      <td>40876</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Akron</td>\n      <td>OH</td>\n      <td>2017</td>\n      <td>47522</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albany</td>\n      <td>GA</td>\n      <td>2017</td>\n      <td>36780</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albany-Lebanon</td>\n      <td>OR</td>\n      <td>2017</td>\n      <td>41169</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albany-Schenectady-Troy</td>\n      <td>NY</td>\n      <td>2017</td>\n      <td>56487</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "#read income csv into a dataframe\n",
    "csv_income = 'Main Avocado Tree (Resources)/income per metropolitan area.csv'\n",
    "income_df = pd.read_csv(csv_income)\n",
    "income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 geography State  year  Per capita personal income\n",
       "0                  Abilene    TX  2017                       40876\n",
       "1                    Akron    OH  2017                       47522\n",
       "2                   Albany    GA  2017                       36780\n",
       "3           Albany-Lebanon    OR  2017                       41169\n",
       "4  Albany-Schenectady-Troy    NY  2017                       56487"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>geography</th>\n      <th>State</th>\n      <th>year</th>\n      <th>Per capita personal income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abilene</td>\n      <td>TX</td>\n      <td>2017</td>\n      <td>40876</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Akron</td>\n      <td>OH</td>\n      <td>2017</td>\n      <td>47522</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albany</td>\n      <td>GA</td>\n      <td>2017</td>\n      <td>36780</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albany-Lebanon</td>\n      <td>OR</td>\n      <td>2017</td>\n      <td>41169</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albany-Schenectady-Troy</td>\n      <td>NY</td>\n      <td>2017</td>\n      <td>56487</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "#Rename columns to match those in Avocado\n",
    "rename_income_df = income_df.rename(columns={\"Geography\": \"geography\", \"Year\":\"year\"})\n",
    "rename_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           date  average_price  total_volume      4046       4225     4770  \\\n",
       "0    2017-01-01           0.64     329279.29   2646.83  130250.60  2530.91   \n",
       "1    2017-01-01           1.23      10798.25    351.72    8558.19     0.00   \n",
       "2    2017-01-08           0.82     285027.21   4147.01  126967.13   991.09   \n",
       "3    2017-01-08           1.07      12346.01    323.43    6801.77     0.00   \n",
       "4    2017-01-15           0.76     346523.78   2939.57  125731.86   994.43   \n",
       "..          ...            ...           ...       ...        ...      ...   \n",
       "303  2019-12-15           1.58       7481.67     60.37     891.36     0.00   \n",
       "304  2019-12-22           0.88     210276.00  85573.42    6270.17   329.50   \n",
       "305  2019-12-22           1.32      10033.83     66.47     698.10     0.00   \n",
       "306  2019-12-29           0.82     230398.16  97961.88    5935.34   219.98   \n",
       "307  2019-12-29           1.20      10132.87     67.47    1017.51     0.00   \n",
       "\n",
       "     total_bags  small_bags  large_bags  xlarge_bags          type  year  \\\n",
       "0     193850.95    30669.35   163180.08         1.52  conventional  2017   \n",
       "1       1888.34      293.33     1595.01         0.00       organic  2017   \n",
       "2     152921.98    33746.17   118612.86       562.95  conventional  2017   \n",
       "3       5220.81      654.36     4566.45         0.00       organic  2017   \n",
       "4     216857.92    29095.07   187759.83         3.02  conventional  2017   \n",
       "..          ...         ...         ...          ...           ...   ...   \n",
       "303     6529.94     3934.64     2595.30         0.00       organic  2019   \n",
       "304   118102.91    96998.28    20685.57       419.06  conventional  2019   \n",
       "305     9269.26     6199.39     3069.87         0.00       organic  2019   \n",
       "306   126280.96   107077.99    18849.51       353.46  conventional  2019   \n",
       "307     9047.89     5774.86     3273.03         0.00       organic  2019   \n",
       "\n",
       "    month day geography-0 geography-1      State  Per capita personal income  \n",
       "0      01  01  Cincinnati      Dayton   OH-KY-IN                       51844  \n",
       "1      01  01  Cincinnati      Dayton   OH-KY-IN                       51844  \n",
       "2      01  08  Cincinnati      Dayton   OH-KY-IN                       51844  \n",
       "3      01  08  Cincinnati      Dayton   OH-KY-IN                       51844  \n",
       "4      01  15  Cincinnati      Dayton   OH-KY-IN                       51844  \n",
       "..    ...  ..         ...         ...        ...                         ...  \n",
       "303    12  15   Nashville        None         TN                       60680  \n",
       "304    12  22   Nashville        None         TN                       60680  \n",
       "305    12  22   Nashville        None         TN                       60680  \n",
       "306    12  29   Nashville        None         TN                       60680  \n",
       "307    12  29   Nashville        None         TN                       60680  \n",
       "\n",
       "[12936 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>average_price</th>\n      <th>total_volume</th>\n      <th>4046</th>\n      <th>4225</th>\n      <th>4770</th>\n      <th>total_bags</th>\n      <th>small_bags</th>\n      <th>large_bags</th>\n      <th>xlarge_bags</th>\n      <th>type</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>geography-0</th>\n      <th>geography-1</th>\n      <th>State</th>\n      <th>Per capita personal income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-01</td>\n      <td>0.64</td>\n      <td>329279.29</td>\n      <td>2646.83</td>\n      <td>130250.60</td>\n      <td>2530.91</td>\n      <td>193850.95</td>\n      <td>30669.35</td>\n      <td>163180.08</td>\n      <td>1.52</td>\n      <td>conventional</td>\n      <td>2017</td>\n      <td>01</td>\n      <td>01</td>\n      <td>Cincinnati</td>\n      <td>Dayton</td>\n      <td>OH-KY-IN</td>\n      <td>51844</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01</td>\n      <td>1.23</td>\n      <td>10798.25</td>\n      <td>351.72</td>\n      <td>8558.19</td>\n      <td>0.00</td>\n      <td>1888.34</td>\n      <td>293.33</td>\n      <td>1595.01</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2017</td>\n      <td>01</td>\n      <td>01</td>\n      <td>Cincinnati</td>\n      <td>Dayton</td>\n      <td>OH-KY-IN</td>\n      <td>51844</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-01-08</td>\n      <td>0.82</td>\n      <td>285027.21</td>\n      <td>4147.01</td>\n      <td>126967.13</td>\n      <td>991.09</td>\n      <td>152921.98</td>\n      <td>33746.17</td>\n      <td>118612.86</td>\n      <td>562.95</td>\n      <td>conventional</td>\n      <td>2017</td>\n      <td>01</td>\n      <td>08</td>\n      <td>Cincinnati</td>\n      <td>Dayton</td>\n      <td>OH-KY-IN</td>\n      <td>51844</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-01-08</td>\n      <td>1.07</td>\n      <td>12346.01</td>\n      <td>323.43</td>\n      <td>6801.77</td>\n      <td>0.00</td>\n      <td>5220.81</td>\n      <td>654.36</td>\n      <td>4566.45</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2017</td>\n      <td>01</td>\n      <td>08</td>\n      <td>Cincinnati</td>\n      <td>Dayton</td>\n      <td>OH-KY-IN</td>\n      <td>51844</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-01-15</td>\n      <td>0.76</td>\n      <td>346523.78</td>\n      <td>2939.57</td>\n      <td>125731.86</td>\n      <td>994.43</td>\n      <td>216857.92</td>\n      <td>29095.07</td>\n      <td>187759.83</td>\n      <td>3.02</td>\n      <td>conventional</td>\n      <td>2017</td>\n      <td>01</td>\n      <td>15</td>\n      <td>Cincinnati</td>\n      <td>Dayton</td>\n      <td>OH-KY-IN</td>\n      <td>51844</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>2019-12-15</td>\n      <td>1.58</td>\n      <td>7481.67</td>\n      <td>60.37</td>\n      <td>891.36</td>\n      <td>0.00</td>\n      <td>6529.94</td>\n      <td>3934.64</td>\n      <td>2595.30</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2019</td>\n      <td>12</td>\n      <td>15</td>\n      <td>Nashville</td>\n      <td>None</td>\n      <td>TN</td>\n      <td>60680</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>2019-12-22</td>\n      <td>0.88</td>\n      <td>210276.00</td>\n      <td>85573.42</td>\n      <td>6270.17</td>\n      <td>329.50</td>\n      <td>118102.91</td>\n      <td>96998.28</td>\n      <td>20685.57</td>\n      <td>419.06</td>\n      <td>conventional</td>\n      <td>2019</td>\n      <td>12</td>\n      <td>22</td>\n      <td>Nashville</td>\n      <td>None</td>\n      <td>TN</td>\n      <td>60680</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>2019-12-22</td>\n      <td>1.32</td>\n      <td>10033.83</td>\n      <td>66.47</td>\n      <td>698.10</td>\n      <td>0.00</td>\n      <td>9269.26</td>\n      <td>6199.39</td>\n      <td>3069.87</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2019</td>\n      <td>12</td>\n      <td>22</td>\n      <td>Nashville</td>\n      <td>None</td>\n      <td>TN</td>\n      <td>60680</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>2019-12-29</td>\n      <td>0.82</td>\n      <td>230398.16</td>\n      <td>97961.88</td>\n      <td>5935.34</td>\n      <td>219.98</td>\n      <td>126280.96</td>\n      <td>107077.99</td>\n      <td>18849.51</td>\n      <td>353.46</td>\n      <td>conventional</td>\n      <td>2019</td>\n      <td>12</td>\n      <td>29</td>\n      <td>Nashville</td>\n      <td>None</td>\n      <td>TN</td>\n      <td>60680</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>2019-12-29</td>\n      <td>1.20</td>\n      <td>10132.87</td>\n      <td>67.47</td>\n      <td>1017.51</td>\n      <td>0.00</td>\n      <td>9047.89</td>\n      <td>5774.86</td>\n      <td>3273.03</td>\n      <td>0.00</td>\n      <td>organic</td>\n      <td>2019</td>\n      <td>12</td>\n      <td>29</td>\n      <td>Nashville</td>\n      <td>None</td>\n      <td>TN</td>\n      <td>60680</td>\n    </tr>\n  </tbody>\n</table>\n<p>12936 rows Ã— 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#convert date into three columns\n",
    "split_cols = avocado_df['date'].str.split('-',expand=True)\n",
    "split_cols.columns = [f'Split-{i}' for i in range(3)]\n",
    "avocado_df = avocado_df.join(split_cols)\n",
    "#rename splits to day, month\n",
    "avocado_df = avocado_df.rename(columns={'Split-1':'month','Split-2':'day'})\n",
    "#drop Split-0 due to redundancy with year column\n",
    "avocado_df = avocado_df.drop(['Split-0'], axis=1)\n",
    "#better geography match\n",
    "#used https://hassavocadoboard.com/category-data to confirm state match to income data\n",
    "#Drop Cities with same name, wrong state from income data\n",
    "#Drop all Springfields except Springfield MA from income data\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Springfield') & (rename_income_df['State'] == 'MO')].index)\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Springfield') & (rename_income_df['State'] == 'IL')].index)\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Springfield') & (rename_income_df['State'] == 'OH')].index)\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Eugene-Springfield') & (rename_income_df['State'] == ' OR')].index)\n",
    "#Drop Albanies not NY from income data\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Albany-Lebanon') & (rename_income_df['State'] == ' OR')].index)\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Albany') & (rename_income_df['State'] == ' GA')].index)\n",
    "#Drop all Columbuses not OH from income data\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Columbus') & (rename_income_df['State'] == ' GA-AL')].index)\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Columbus') & (rename_income_df['State'] == ' IN')].index)\n",
    "#Drop all Jacksonvilles not FL\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Jacksonville') & (rename_income_df['State'] == ' NC')].index)\n",
    "#Drop all Portlands not OR\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Portland-South Portland') & (rename_income_df['State'] == ' ME')].index)\n",
    "#Drop all Rochesters not NY\n",
    "rename_income_df = rename_income_df.drop(rename_income_df[(rename_income_df['geography'] == 'Rochester') & (rename_income_df['State'] == ' MN')].index)\n",
    "\n",
    "#text to column cities in income and avocado data\n",
    "columnTOtext1 = rename_income_df['geography'].str.split('-',expand=True)\n",
    "columnTOtext1.columns = [f'geography-{i}' for i in range(4)]\n",
    "new_income = rename_income_df.join(columnTOtext1)\n",
    "new_income = new_income.drop(['geography'], axis=1)\n",
    "columnTOtext = avocado_df['geography'].str.split('/',expand=True)\n",
    "columnTOtext.columns = [f'geography-{i}' for i in range(2)]\n",
    "new_avocado = avocado_df.join(columnTOtext)\n",
    "new_avocado = new_avocado.drop(['geography'], axis=1)\n",
    "\n",
    "#keep rows that only have one city\n",
    "second_cities = new_income['geography-1'].unique()\n",
    "second_cities = second_cities.tolist()\n",
    "del second_cities[0]\n",
    "\n",
    "new_income_first = new_income[~new_income['geography-1'].isin(second_cities)]\n",
    "new_income_first = new_income_first.drop(['geography-1', 'geography-2', 'geography-3'], axis=1)\n",
    "#merge data frame based on new_income_first\n",
    "first = new_avocado.merge(new_income_first, how='inner', on=['geography-0', 'year'])\n",
    "first_geo_0 = first['geography-0'].unique()\n",
    "first_geo_0 = first_geo_0.tolist()\n",
    "first_geo_1 = first['geography-1'].unique()\n",
    "#remove already merged cities from new_avocado\n",
    "new_avocado = new_avocado[~new_avocado['geography-0'].isin(first_geo_0)]\n",
    "#keep rows that only have a two cities\n",
    "new_income_second = new_income.dropna(subset=['geography-1'])\n",
    "new_avocado_second = new_avocado.dropna(subset=['geography-1'])\n",
    "third_cities = new_income_second['geography-2'].unique()\n",
    "third_cities = third_cities.tolist()\n",
    "del third_cities[2]\n",
    "\n",
    "new_income_second = new_income_second[~new_income_second['geography-2'].isin(third_cities)]\n",
    "new_income_second = new_income_second.drop(['geography-2', 'geography-3'], axis=1)\n",
    "\n",
    "#merge data frame based on new_income_second\n",
    "second = new_avocado.merge(new_income_second, how='inner', on=['geography-0', 'year'])\n",
    "second = second.drop(['geography-1_y'], axis=1)\n",
    "second = second.rename(columns={'geography-1_x':'geography-1'})\n",
    "second_geo_0 = second['geography-0'].unique()\n",
    "second_geo_0 = second_geo_0.tolist()\n",
    "#remove already merged cities\n",
    "new_avocado = new_avocado[~new_avocado['geography-0'].isin(second_geo_0)]\n",
    "#keep rows that only have a three cities\n",
    "new_income_third = new_income.dropna(subset=['geography-2'])\n",
    "fourth_cities = new_income_third['geography-3'].unique()\n",
    "fourth_cities = fourth_cities.tolist()\n",
    "del fourth_cities[0]\n",
    "\n",
    "new_income_third = new_income_third[~new_income_third['geography-3'].isin(fourth_cities)]\n",
    "new_income_third = new_income_third.drop(['geography-3'], axis=1)\n",
    "\n",
    "#merge dataframes\n",
    "third = new_avocado.merge(new_income_third, how='inner', on=['geography-0', 'year'])\n",
    "third = third.drop(['geography-1_y', 'geography-2'], axis=1)\n",
    "third = third.rename(columns={'geography-1_x':'geography-1'})\n",
    "third_geo_0 = third['geography-0'].unique()\n",
    "third_geo_0 = third_geo_0.tolist()\n",
    "#remove already merged cities\n",
    "new_avocado = new_avocado[~new_avocado['geography-0'].isin(third_geo_0)]\n",
    "#keep rows that only have a four cities\n",
    "new_income_fourth = new_income.dropna(subset=['geography-3'])\n",
    "\n",
    "#merge dataframes\n",
    "fourth = new_avocado.merge(new_income_fourth, how='inner', on=['geography-0', 'year'])\n",
    "fourth = fourth.drop(['geography-1_y', 'geography-2', 'geography-3'], axis=1)\n",
    "fourth = fourth.rename(columns={'geography-1_x':'geography-1'})\n",
    "\n",
    "#combine merged dataframes into one\n",
    "income_avocado = first.append(second)\n",
    "income_avocado = income_avocado.append(third)\n",
    "income_avocado = income_avocado.append(fourth)\n",
    "\n",
    "#get list of cities in dataframe\n",
    "unique_cities = income_avocado['geography-0'].unique()\n",
    "unique_cities = unique_cities.tolist()\n",
    "income_avocado.reset_index()\n",
    "income_avocado\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Which cities love avocados most?\n",
    "\n",
    "#Task 1: popularity of avocado, visual heatmap, 2015 to 2020, bar graph of volume per area "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-be6e4353771d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mincome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpurchased\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinregress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mregress_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_values\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mslope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mline_eq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"y = \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"x + \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_mstats_common.py\u001b[0m in \u001b[0;36mlinregress\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# average sum of squares:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mssxm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssxym\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssyxm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[0mr_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mssxym\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mr_den\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mssxm\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mssym\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "#Question 2: Do states with higher income per capita buy more avocados? (income per capita from 2017-2019)\n",
    "income = income_avocado.loc[:,['Per capita personal income']]\n",
    "purchased = income_avocado.loc[:,['total_volume']]\n",
    "x_values = income\n",
    "y_values = purchased\n",
    "(slope, intercept, rvalue, pvalue, stderr) = st.linregress(x_values, y_values)\n",
    "regress_values = x_values*slope + intercept\n",
    "line_eq = \"y = \" +str(round(slope,2)) + \"x + \" + str(round(intercept, 2))\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.scatter(income_avocado.loc[:,['Per capita personal income']], income_avocado.loc[:,['total_volume']])\n",
    "ax1.plot(x_values, regress_values, \"r-\")\n",
    "ax1.annotate(line_eq,(6,10),fontsize=15,color=\"green\")\n",
    "ax1.set_xlabel('Income Per Capita')\n",
    "ax1.set_ylabel('Avocados Purchased')\n",
    "fig.set_size_inches(10, 10)\n",
    "plt.show()\n",
    "\n",
    "correlation = st.pearsonr(income, purchased)\n",
    "print(f\"The correlation between both factors is {round(correlation[0], 2)}\")\n",
    "\n",
    "\n",
    "#Task 2: line graph (x-values states, y-values income per capita and avocado revenue) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3: Which type of avocado is the biggest source of revenue for suppliers? Erica\n",
    "\n",
    "#create revenue column\n",
    "income_avocado['revenue'] = round(income_avocado['average_price']*income_avocado['total_volume'], 2)\n",
    "\n",
    "#list of unique years in data\n",
    "years = income_avocado['year'].unique()\n",
    "years = years.tolist()\n",
    "years\n",
    "#list of unique types in data\n",
    "types = income_avocado['type'].unique()\n",
    "types = types.tolist()\n",
    "#seperate into dataframes for each year\n",
    "typeANDrevenue_2017 = income_avocado.loc[income_avocado['year']==2017, ['type', 'revenue']]\n",
    "typeANDrevenue_2018 = income_avocado.loc[income_avocado['year']==2018, ['type', 'revenue']]\n",
    "typeANDrevenue_2019 = income_avocado.loc[income_avocado['year']==2019, ['type', 'revenue']]\n",
    "#grouping by type\n",
    "grouped_2017 = typeANDrevenue_2017.groupby('type')\n",
    "grouped_2018 = typeANDrevenue_2018.groupby('type')\n",
    "grouped_2019 = typeANDrevenue_2019.groupby('type')\n",
    "#sum of revenues\n",
    "revenues_2017 = grouped_2017.sum()\n",
    "revenues_2018 = grouped_2018.sum()\n",
    "revenues_2019 = grouped_2019.sum()\n",
    "#Task 3: Three pie charts by type (value = revenue) for each year on one png \n",
    "colors = ['green', 'lightgreen']\n",
    "explode = explode = (0.1,0)\n",
    "#create subplots\n",
    "figure, (ax1, ax2, ax3) = plt.subplots(1,3,subplot_kw={'aspect':'equal'})\n",
    "ax1.pie(revenues_2017['revenue'], explode=(0.1,0), labels=types, colors=colors, autopct=\"%1.1f%%\", shadow=True, startangle=140)\n",
    "ax2.pie(revenues_2018['revenue'], explode=(0.1,0), labels=types, colors=colors, autopct=\"%1.1f%%\", shadow=True, startangle=140)\n",
    "ax3.pie(revenues_2019['revenue'], explode=(0.1,0), labels=types, colors=colors, autopct=\"%1.1f%%\", shadow=True, startangle=140)\n",
    "#format\n",
    "ax1.set_xlabel('2017')\n",
    "ax2.set_xlabel('2018')\n",
    "ax3.set_xlabel('2019')\n",
    "ax2.set_title(\"Proportions of Revenue by Avocado Type for Each Year\")\n",
    "\n",
    "plt.show()\n",
    "#fig.savefig('RevenueByTypeByYear.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4: Is there a time of year that sees a spike in revenue? Erica\n",
    "#create a list of months for setting the month column as categorical type\n",
    "#'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "#use calendar import to map month names to corresponding integer \n",
    "income_avocado.sort_values(by=\"date\")\n",
    "income_avocado.reset_index()\n",
    "income_avocado['month'] = pd.to_numeric(income_avocado['month'])\n",
    "income_avocado['day'] = pd.to_numeric(income_avocado['day'])\n",
    "income_avocado['month'] = income_avocado[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "months = income_avocado['month'].unique()\n",
    "months = months.tolist()\n",
    "#make categorical, so column can be sorted by index of months list\n",
    "income_avocado['month'] = pd.Categorical(income_avocado['month'], categories=months)\n",
    "\n",
    "#pivot data, so there's a column for each month, each row has year and sum of revenue column\n",
    "pd.options.display.float_format = '{:, .2f}'.format\n",
    "income_avocado_pivot = pd.pivot_table(income_avocado, values='revenue', index='year', columns='month', aggfunc=np.sum)\n",
    "\n",
    "#plot a bar chart using the pivoted data\n",
    "ax1 = income_avocado_pivot.plot(kind=\"bar\")\n",
    "#get a Matplotlib figure from the axes object for formatting purposes\n",
    "fig = ax1.get_figure()\n",
    "#change the plot dimensions (width, height)\n",
    "fig.set_size_inches(7, 6)\n",
    "#change the axes labels\n",
    "ax1.set_xlabel(\"Years\")\n",
    "ax1.set_ylabel(\"Total Revenues Per Month ($100 Millions)\")\n",
    "ax1.legend(fancybox=True, bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "ax1.grid(True)\n",
    "# Use this to show the plot in a new window\n",
    "plt.show()\n",
    "# Export the plot as a PNG file\n",
    "#fig.savefig('RevenueByMonthByYear.png\")\n",
    "#Task 4: bar chart (x-values months, y-values avocado revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5: How has the average avocado price changed over time?  What is the predicted avocado price for 2021 based on our data?  Bitty\n",
    "\n",
    "#Task 5: scatter plot with regression to predict 2021 average price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6: Do different types of avocados have different price trends? Arianne\n",
    "\n",
    "#Task 6: facet (multiple lines on one) line graph (x-values = year, y-values = average price) for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at volume for 4046\n",
    "plot_4046 = [['4046','year','average_price']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at volume for 4225\n",
    "plot_4225= [['4225', 'year', 'average_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at Volume for 4770\n",
    "plot_4770 = [['4770', 'year', 'average_price']]\n"
   ]
  }
 ]
}